# Papers

## layout

[Page segmentation using convolutional neural network and graphical model](https://link.springer.com/chapter/10.1007/978-3-030-57058-3_17) -Lixiaohui, DAS2020<br>
 [Printed/Handwritten Texts and Graphics Separation in Complex Documents Using Conditional Random Fields](https://ieeexplore.ieee.org/abstract/document/8395186) -LiXiaohui, DAS2018<br>

## asr

[Conformer: Convolution-augmented Transformer for Speech Recognition](https://arxiv.org/abs/2005.08100) -google, Interspeech2020, [code1](https://github.com/sooftware/conformer),[code2](https://github.com/thu-spmi/CAT)<br>
 [ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context](https://arxiv.org/abs/2005.03191) -google, Interspeech2020, [code](https://github.com/hasangchun/ContextNet)<br>
 [Investigation of modeling units for mandarin speech recognition using DFSMN-CTC-sMBR](https://ieeexplore.ieee.org/abstract/document/8683859) -alibaba, ICASSP2019<br>
 [Sequence discriminative distributed training of long short-term memory recurrent neural networks](https://research.google/pubs/pub42547/) -google, <br>
 [Sequence-discriminative training of deep neural networks](http://www.fit.vutbr.cz/research/groups/speech/publi/2013/vesely_interspeech2013_IS131333.pdf) INTERSPEECH2013<br>

## Contextual Biasing

[Improved recognition of contact names in voice commands]() -google, ICASSP2015<br>
 [Bringing contextual information to google speech recognition](https://www.semanticscholar.org/paper/Bringing-contextual-information-to-google-speech-Aleksic-Ghodsi/740844739cd791e9784c4fc843beb9174ed0b487?p2df) -google, INTERSPEECH2015<br>
 [Shallow-Fusion End-to-End Contextual Biasing]() -google, INTERSPEECH2019<br>
 [Streaming End-to-end Speech Recognition for Mobile Devices](https://arxiv.org/abs/1811.06621) -google, ICASSP2019<br>

## table detection & recognition

[Robust Table Detection and Structure Recognition from Heterogeneous Document Images](https://arxiv.org/abs/2203.09056) -huoqiang, arxiv2022<br>
 [Deep Structured Feature Networks for Table Detection and Tabular Data Extraction from Scanned Financial Document Images](https://arxiv.org/abs/2102.10287) -arxiv2021<br>
 [Guided Table Structure Recognition through Anchor Optimization](https://arxiv.org/abs/2104.10538) -arxiv2021<br>
 [TabAug: Data Driven Augmentation for Enhanced Table Structure Recognition](https://arxiv.org/abs/2104.14237) -ICDAR2021<br>
 [PingAn-VCGroup's Solution for ICDAR 2021 Competition on Scientific Table Image Recognition to Latex](https://arxiv.org/abs/2105.01846) -pingan, arxiv2021<br>
 [LGPMA: Complicated Table Structure Recognition with Local and Global Pyramid Mask Alignment](https://arxiv.org/abs/2105.06224) -ICDAR2021<br>
 [ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX](https://arxiv.org/abs/2105.14426) -arxiv2021<br>
 [TGRNet: A Table Graph Reconstruction Network for Table Structure Recognition](https://arxiv.org/abs/2106.10598) JD-ICCV2021, [code](https://github.com/xuewenyuan/TGRNet)<br>
 [Parsing Table Structures in the Wild](https://arxiv.org/abs/2109.02199) -alibaba, ICCV2021, [dataset](https://github.com/wangwen-whu/WTW-Dataset)<br>
 [TNCR: Table Net Detection and Classification Dataset](https://github.com/abdoelsayed2016/TNCR_Dataset) -arxiv2021, [dataset](https://github.com/abdoelsayed2016/TNCR_Dataset)<br>
 [Form2Seq : A Framework for Higher-Order Form Structure Extraction](https://arxiv.org/abs/2107.04419) -EMNLP2020<br>
 [Table Structure Recognition using Top-Down and Bottom-Up Cues](https://arxiv.org/abs/2010.04565) ECCV2020<br>
 [Tablenet: Deep learning model for end-to-end table detection and tabular data extraction from scanned document images](https://arxiv.org/abs/2001.01469) -ICDAR2019<br>
 [Image-based table recognition: data, model, and evaluation](https://arxiv.org/abs/1911.10683) -arxiv2019<br>
 [Deep Splitting and Merging for Table Structure Decomposition](https://ieeexplore.ieee.org/document/8977975) -ICDAR2019<br>
 [Deepdesrt: Deep learning for detection and structure recognition of tables in document images](https://ieeexplore.ieee.org/abstract/document/8270123) -ICDAR2017<br>

## mathematical expression recognition

[When Counting Meets HMER: Counting-Aware Network for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2207.11463) -baixiang, ECCV2022, [code](https://github.com/LBH1024/CAN)<br>
 [Handwritten Mathematical Expression Recognition via Attention Aggregation based Bi-directional Mutual Learning](https://ojs.aaai.org/index.php/AAAI/article/view/19885) -tencent, AAAI2022, [code](https://github.com/XH-B/ABM)<br>
 [Handwritten Mathematical Expression Recognition with Bidirectionally Trained Transformer](https://arxiv.org/abs/2105.02412) -huawei, ICDAR2021<br>
 [Graph-to-graph: towards accurate and interpretable online handwritten mathematical expression recognition](https://ojs.aaai.org/index.php/AAAI/article/view/16399) -wujinwen, AAAI2021<br>
 [ICFHR 2020 Competition on Offline Recognition and Spotting of Handwritten Mathematical Expressions - OffRaSHME](https://ieeexplore.ieee.org/abstract/document/9257745) -Wangdahan, ICFHR2020<br>
 [Improvement of End-to-End Offline Handwritten Mathematical Expression Recognition by Weakly Supervised Learning](https://ieeexplore.ieee.org/abstract/document/9257749) -ICFHR2020<br>
 [Improving Attention-Based Handwritten Mathematical Expression Recognition with Scale Augmentation and Drop Attention](https://ieeexplore.ieee.org/abstract/document/9257765) -Jinlianwen, ICFHR2020<br>
 [EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for Printed Mathematical Expression Recognition](https://arxiv.org/abs/2007.02517) -arxiv2020, [code](https://github.com/abcAnonymous/EDSL)<br>
 [Handwritten mathematical expression recognition via paired adversarial learning](https://link.springer.com/article/10.1007%2Fs11263-020-01291-5) -WuJinwen, IJCV2020<br>
 [Stroke Constrained Attention Network for Online Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2002.08670) -DuJun, arxiv2020, [code]()<br>
 [SRD: A Tree Structure Based Decoder for Online Handwritten Mathematical Expression Recognition](https://ieeexplore.ieee.org/abstract/document/9147045/) -DuJun, TMM2020, [code](https://github.com/Rid7/SRD)<br>
 [A Tree-Structured Decoder for Image-to-Markup Generation]() -Dujun, ICML2020, [code](https://github.com/JianshuZhang/TreeDecoder)<br>
 [Multi-modal Attention Network for Handwritten Mathematical Expression Recognition](https://ieeexplore.ieee.org/abstract/document/8978103/) -DuJun, ICDAR2019<br>
 [Robust Encoder-Decoder Learning Framework towards Offline Handwritten Mathematical Expression Recognition Based on Multi-Scale Deep Neural Network](https://arxiv.org/abs/1902.05376)-arxiv2019<br>
 [Track, attend, and parse (tap): An end-to-end framework for online handwritten mathematical expression recognition](https://ieeexplore.ieee.org/abstract/document/8373726) -DuJun, TMM2018, [code](https://github.com/JianshuZhang/TAP)<br>
 [Multi-scale attention with dense encoder for handwritten mathematical expression recognition](https://ieeexplore.ieee.org/abstract/document/8546031) -DuJun, ICPR2018, [code](https://github.com/JianshuZhang/WAP)<br>
 [Watch, attend and parse: An end-to-end neural network based approach to handwritten mathematical expression recognition](https://www.sciencedirect.com/science/article/pii/S0031320317302376) -J Zhang, J Du, S Zhang, D Liu, Y Hu, J Hu, S Wei, PR2017, [code](https://github.com/JianshuZhang/WAP), [code2](https://github.com/whywhs/Pytorch-Handwritten-Mathematical-Expression-Recognition)<br>
 [A GRU-Based Encoder-Decoder Approach with Attention for Online Handwritten Mathematical Expression Recognition](https://ieeexplore.ieee.org/abstract/document/8270083) -Dujun, ICDAR2017, [code](https://github.com/JianshuZhang/TAP)<br>
 [Image-to-markup generation with coarse-to-fine attention](http://proceedings.mlr.press/v70/deng17a.html) -Dengyuntian, ICML2017, [code](https://github.com/harvardnlp/im2markup/)<br>
 [What you get is what you see: A visual markup decompiler](https://arxiv.org/abs/1609.04938) -Dengyuntian, arxiv2016, [code](https://github.com/OpenNMT/OpenNMT-py/blob/master/docs/source/legacy/im2text.md)<br>
 [Context-aware mathematical expression recognition: An end-to-end framework and a benchmark](https://ieeexplore.ieee.org/abstract/document/7900135) -Hewenhao, ICPR2016<br>
 [ICFHR2016 CROHME: Competition on Recognition of Online Handwritten Mathematical Expressions](https://ieeexplore.ieee.org/abstract/document/7814132) -ICFHR2016<br>
 [An integrated grammar-based approach for mathematical expression recognition](https://www.sciencedirect.com/science/article/abs/pii/S0031320315003441) -PR2016<br>

## word_vector

[Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606)--FAIR, arxiv2016<br>
 [fastText-Bag of Tricks for Efficient Text Classification](https://arxiv.org/abs/1607.01759)-FAIR, arxiv2016<br>
 [An empirical evaluation of doc2vec with practical insights into document embedding generation](https://arxiv.org/abs/1607.05368)-Jey Han Lau, Timothy Baldwin, arxiv2016<br>
 [TagSpace：Semantic Embeddings from Hashtags](http://www.aclweb.org/anthology/D14-1194)-FAIR, EMNLP2014<br>
 [doc2vec-Distributed Representations of Sentences and Documents](http://proceedings.mlr.press/v32/le14.pdf)-google, ICML2014<br>
 [word2vec-Efficient estimation of word representations in vector space](https://arxiv.org/abs/1301.3781)-google, ICLR2013<br>

## Seq2Seq

[Convolutional Sequence to Sequence Learning](https://arxiv.org/abs/1705.03122) -FAIR, arxiv2017<br>
 [A Convolutional Encoder Model for Neural Machine Translation](https://arxiv.org/abs/1611.02344)-FAIR, arxiv2016<br>
 [Sequence level training with recurrent neural networks](https://arxiv.org/abs/1511.06732)-FAIR, ICLR2016<br>

## ReID

[Alignedreid: Surpassing human-level performance in person re-identification](https://arxiv.org/abs/1711.08184) -Face++, arxiv2017<br>

## PoseEstimation

[Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1611.08050) -CMU, CVPR2017<br>
 AlphaPose<br>

## EdgeDetection

[Pixel Difference Networks for Efficient Edge Detection](https://arxiv.org/abs/2108.07009) -ICCV2021, [code](https://github.com/zhuoinoulu/pidinet)<br>
 [Richer Convolutional Features for Edge Detection](http://mftp.mmcheng.net/Papers/19PamiEdge.pdf) -YunLiu, ..., Baixiang et, PAMI2019<br>
 [Deepedge: A multi-scale bifurcated deep network for top-down contour detection](https://www.seas.upenn.edu/~gberta/uploads/3/1/4/8/31486883/1950.pdf) -Gedas, CVPR15<br>

## line segmentation

[M-LSD: Towards Light-weight and Real-time Line Segment Detection](https://arxiv.org/abs/2106.00186) -NAVER, AAAI2022, [code](https://github.com/navervision/mlsd)<br>
 [Deep Hough Transform for Semantic Line Detection](https://arxiv.org/abs/2003.04676) -PAMI2021, [code](https://github.com/Hanqer/deep-hough-transform)<br>
 [Holistically-Attracted Wireframe Parsing](https://arxiv.org/abs/2003.01663) -CVPR2020, [code](https://github.com/cherubicXN/hawp)<br>
 [EDlines](https://github.com/mtamburrano/LBD_Descriptor)<br>

## video_classification

[Learnable pooling with Context Gating for video classification](https://arxiv.org/abs/1706.06905) -A. Miech, et al, TPAMI2018, Youtube8M-Competition-Top1<br>
 [Truly Multi-modal YouTube-8M Video Classification with Video, Audio, and Text](https://arxiv.org/abs/1706.05461) -Zhe wang, et al, arxiv2017<br>

## dnn_base

[Group Normalization](https://arxiv.org/abs/1803.08494) -Kaiming He, et al, arxiv2018<br>
[Graph Convolutional Network](https://arxiv.org/abs/1803.08035) -Xiaolong Wang, Yufei Ye, Abhinav Gupta, CVPR2018<br>
DetNAS: Backbone Search for Object Detection<br>
Mixup<br>

## light network

[UniFormer: Unified Transformer for Efficient Spatiotemporal Representation Learning](https://arxiv.org/abs/2201.04676) -ICLR2022,[code](https://github.com/Sense-X/UniFormer)<br>
[EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications](https://arxiv.org/abs/2206.10589) -arxiv2022, [code](https://github.com/mmaaz60/EdgeNeXt)<br>
[EfficientFormer: Vision Transformers at MobileNet Speed](https://arxiv.org/abs/2206.01191) -apple, arxiv2022, [code](https://github.com/snap-research/EfficientFormer)<br>
[UNeXt: MLP-based Rapid Medical Image Segmentation Network](https://arxiv.org/abs/2203.04967) -arxiv2022, [code](https://github.com/jeya-maria-jose/UNeXt-pytorch)<br>
[TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation](https://arxiv.org/abs/2204.05525) -tencent, CVPR2022, [code](https://github.com/hustvl/TopFormer)<br>
[MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer](https://arxiv.org/abs/2110.02178) apple, ICLR2022, [code](https://github.com/apple/ml-cvnets)<br>
TinyNet[Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets](https://arxiv.org/abs/2010.14819) -huawei, NeurIPS2020<br>
[GhostNet: More Features from Cheap Operations](https://arxiv.org/abs/1911.11907) -huawei, CVPR2020<br>
EfficientNet<br>
SqueezeNet<br>
[Mobilenets](https://arxiv.org/abs/1704.04861) -google, arxiv2017<br>
[MobileNet-V2](https://arxiv.org/abs/1801.04381) -google, CVPR2018 [caffe-code](https://github.com/austingg/MobileNet-v2-caffe)<br>
MobileNetV3<br>
[NasNet-A-Learning transferable architectures for scalable image recognition](https://arxiv.org/abs/1707.07012) -google brain, CoRR2017<br>
[ShuffleNet](https://arxiv.org/abs/1707.01083) -megvii, CoRR2017<br>
ShuffleNetV2<br>
ThunderNet<br>
DarkNet/Tiny YOLOv3/Tiny YOLOv2/Yolo-Nano/SlimYOLO/YOLO-LITE/Gaussian YOLOv3<br>
[LightweightNet: Toward fast and lightweight convolutional neural networks via architecture distillation](https://www.sciencedirect.com/science/article/abs/pii/S0031320318303807) -XuTingbin, PR2019<br>
Mobilefacenets<br>
EXTD: Extremely Tiny Face Detector via Iterative Filter Reuse<br>
Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution<br>
HetConv: Heterogeneous Kernel-Based Convolutions for Deep CNNs<br>
Joint Architecture and Knowledge Distillation in Convolutional Neural Network for Offline Handwritten Chinese Text Recognition -dujun, arxiv2019
Compressing CNN-DBLSTM models for OCR with teacher-student learning and Tucker decomposition -huoqiang, PR2019
[vovnet](https://arxiv.org/abs/1904.09730)<br>
http://openaccess.thecvf.com/content_CVPRW_2019/papers/CEFRL/Lee_An_Energy_and_GPU-Computation_Efficient_Backbone_Network_for_Real-Time_Object_CVPRW_2019_paper.pdf

## network

[Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios](https://arxiv.org/abs/2207.05501) -bytedance, arxiv2022<br>
[TRT-ViT: TensorRT-oriented Vision Transformer](https://arxiv.org/abs/2205.09579) -bytedance, arxiv2022<br>

## model compression

蒸馏：teacher-student/mutual-learning/Self-Distillation<br>
张量分解：low-rank/SVD-decomposition/Tucker-decomposition/CP-decomposition<br>
剪枝<br>
量化<br>
编码<br>

## InformationExtraction

[LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking](https://arxiv.org/abs/2204.08387) -microsoft, arxiv2022, [code](https://github.com/microsoft/unilm/tree/master/layoutlmv3)<br>
[LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding](https://arxiv.org/abs/2202.13669) -jinlianwen, ACL2022, [code](https://github.com/jpWang/LiLT)<br>
[XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich Document Understanding](https://arxiv.org/abs/2203.06947) -ant group, CVPR2022<br>
[BROS: A Pre-trained Language Model Focusing on Text and Layout for Better Key Information Extraction from Documents](https://arxiv.org/abs/2108.04539) -naver, AAAI2022, [code](https://github.com/clovaai/bros)<br>
[StructuralLM: Structural Pre-training for Form Understanding](https://arxiv.org/abs/2105.11210) -alibaba, ACL2021<br>
[UniDoc: Unified Pretraining Framework for Document Understanding](https://proceedings.neurips.cc/paper/2021/hash/0084ae4bc24c0795d1e6a4f58444d39b-Abstract.html) -adobe, NeurIPS2021<br>
[DocFormer: End-to-End Transformer for Document Understanding](https://openaccess.thecvf.com/content/ICCV2021/html/Appalaraju_DocFormer_End-to-End_Transformer_for_Document_Understanding_ICCV_2021_paper.html) -amazon, ICCV2021<br>
[LayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis](https://link.springer.com/chapter/10.1007/978-3-030-86549-8_9) -ICDAR2021<br>
[Going Full-TILT Boogie on Document Understanding with Text-Image-Layout Transformer](https://arxiv.org/abs/2102.09550) -ICDAR2021<br>
[Towards Robust Visual Information Extraction in Real World: New Dataset and Novel Solution](https://arxiv.org/abs/2102.06732) -jinlianwen, AAAI2021<br>
[LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding](https://arxiv.org/abs/2104.08836) -microsoft,arxiv2021<br>
[LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740) -microsoft, ACL2021, [code](https://github.com/microsoft/unilm/tree/master/layoutlmv2)<br>
[SelfDoc: Self-Supervised Document Representation Learning](https://arxiv.org/abs/2106.03331) -adobe, CVPR2021<br>
[Going full-tilt boogie on document understanding with text-image-layout transformer](https://arxiv.org/abs/2102.09550) -ICDAR2021<br>
[LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318) -microsoft, KDD2020, [code](https://github.com/microsoft/unilm/tree/master/layoutlm)<br>
[TRIE: End-to-End Text Reading and Information Extraction for Document Understanding](https://arxiv.org/abs/2005.13118) -hikvision, arxiv2020<br>

## knowledge distillation

[Decoupled Knowledge Distillation](https://arxiv.org/abs/2203.08679) -megvii, CVPR2022, [code](https://github.com/megvii-research/mdistiller)<br>
[Efficient knowledge distillation for rnn-transducer models](https://ieeexplore.ieee.org/abstract/document/9413905) -google/facebook, ICASSP2021<br>
[Investigation of Sequence-level Knowledge Distillation Methods for CTC Acoustic Models](https://ieeexplore.ieee.org/document/8682671) -NICT japan, ICASSP2019<br>
[Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation](https://arxiv.org/abs/1904.08311) -IBM, Interspeech2019<br>
[Explaining sequence-level knowledge distillation as data-augmentation for neural machine translation](https://arxiv.org/abs/1912.03334) -arxiv2019<br>
[Token-Level Ensemble Distillation for Grapheme-to-Phoneme Conversion](https://arxiv.org/abs/1904.03446) -microsoft, Interspeech2019<br>
[Knowledge Distillation for Sequence Model](https://www.researchgate.net/publication/327389374_Knowledge_Distillation_for_Sequence_Model) -AISpeech, Interspeech2018<br>
[Improved knowledge distillation from bi-directional to uni-directional LSTM CTC for end-to-end speech recognition](https://ieeexplore.ieee.org/abstract/document/8639629) -IBM, SLT2018<br>
[An Investigation of a Knowledge Distillation Method for CTC Acoustic Models](https://ieeexplore.ieee.org/document/8461995) -NICT japan, ICASSP2018<br>
[Sequence-Level Knowledge Distillation](https://arxiv.org/abs/1606.07947) -Yoon Kim, EMNLP2016<br>

## Document Rectification

[Fourier Document Restoration for Robust Document Dewarping and Recognition](http://arxiv-export-lb.library.cornell.edu/abs/2203.09910) -CVPR2022, bai song [database](https://sg-vilab.github.io/event/warpdoc/)<br>
[Document Dewarping with Control Points](https://arxiv.org/abs/2203.10543) -ICDAR2021, [code&dataset](https://github.com/gwxie/Document-Dewarping-with-Control-Points)<br>
[Document Rectification and Illumination Correction using a Patch-based CNN](https://arxiv.org/abs/1909.09470) -SIGGRAPH2019, [code](https://github.com/HCIILAB/DocProj)<br>

## Graph

[Joint stroke classification and text line grouping in online handwritten documents with edge pooling attention networks](https://www.sciencedirect.com/science/article/abs/pii/S0031320321000467) -PR2021<br>
[A Comprehensive Survey on Graph Neural Networks](https://ieeexplore.ieee.org/abstract/document/9046288) -TNN2020<br>
[Contextual Stroke Classification in Online Handwritten Documents with Edge Graph Attention Networks](https://link.springer.com/article/10.1007/s42979-020-00177-0) -SNCS2020<br>
[Deepgcns: Can gcns go as deep as cnns?](https://openaccess.thecvf.com/content_ICCV_2019/html/Li_DeepGCNs_Can_GCNs_Go_As_Deep_As_CNNs_ICCV_2019_paper.html) -ICCV2019<br>
[Heterogeneous graph attention network](https://arxiv.org/abs/1903.07293) -WWW2019<br>
[Contextual Stroke Classification in Online Handwritten Documents with Graph Attention Networks](https://ieeexplore.ieee.org/abstract/document/8978003) -ICDAR2019<br>
[Graph Convolutional Networks for Text Classification](https://ojs.aaai.org/index.php/AAAI/article/view/4725) -AAAI2019<br>
[Graph Attention Networks](https://arxiv.org/abs/1710.10903) -ICLR2018<br>
[Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907) -ICLR2017<br>

## super resolution

[Real-esrgan: Training real-world blind super-resolution with pure synthetic data](https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.html) -tencent, ICCV2021, [code](https://github.com/xinntao/Real-ESRGAN)<br>
[Edge-oriented Convolution Block for Real-time Super Resolution on Mobile Devices](https://www4.comp.polyu.edu.hk/~cslzhang/paper/MM21_ECBSR.pdf) -alibaba, ACMMM2021[code](https://github.com/xindongzhang/ECBSR)<br>
[SplitSR: An End-to-End Approach to Super-Resolution on Mobile Devices](https://arxiv.org/abs/2101.07996) -arxiv2021, [code](https://github.com/deepconsc/SplitSR)<br>
[Extremely Lightweight Quantization Robust Real-Time Single-Image Super Resolution for Mobile Devices](https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ayazoglu_Extremely_Lightweight_Quantization_Robust_Real-Time_Single-Image_Super_Resolution_for_Mobile_CVPRW_2021_paper.html) -CVPR2021, [code](https://github.com/cxzhou95/XLSR)<br>

## deblur

[Towards Efficient and Scale-Robust Ultra-High-Definition Image Demoireing](https://arxiv.org/abs/2207.09935) -TCL, ECCV2022, [database/code](https://xinyu-andy.github.io/uhdm-page/)<br>
[Global-Local Stepwise Generative Network for Ultra High-Resolution Image Restoration](https://arxiv.org/abs/2207.08808?context=cs) -arxiv2022<br>
[A Survey on Deep learning based Document Image Enhancement](https://arxiv.org/abs/2112.02719) -arxiv2021<br>
[NTIRE 2021 challenge for defocus deblurring using dual-pixel images: Methods and results](https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Abuolaim_NTIRE_2021_Challenge_for_Defocus_Deblurring_Using_Dual-Pixel_Images_Methods_CVPRW_2021_paper.html?ref=https://githubhelp.com) -CVPR2021, [code](https://aistudio.baidu.com/aistudio/projectdetail/3462083)<br>
[Multi-Stage Progressive Image Restoration](https://openaccess.thecvf.com/content/CVPR2021/html/Zamir_Multi-Stage_Progressive_Image_Restoration_CVPR_2021_paper.html) -google, CVPR2021, [code](https://github.com/swz30/MPRNet)<br>
[Learning frequency domain priors for image demoireing](https://ieeexplore.ieee.org/abstract/document/9547736) -PAMI2021, [code](https://github.com/zhenngbolun/Learnbale_Bandpass_Filter)<br>
[Morié Attack (MA): A New Potential Risk of Screen Photos](https://proceedings.neurips.cc/paper/2021/hash/db9eeb7e678863649bce209842e0d164-Abstract.html) -NIPs2021, [code](https://github.com/Dantong88/Moire_Attack)<br>
[Image demoireing with learnable bandpass filters](https://openaccess.thecvf.com/content_CVPR_2020/html/Zheng_Image_Demoireing_with_Learnable_Bandpass_Filters_CVPR_2020_paper.html) -CVPR2020, [code](https://github.com/zhenngbolun/Learnbale_Bandpass_Filter)<br>
[WDNet: Watermark-Decomposition Network for Visible Watermark Removal](https://arxiv.org/abs/2012.07616) -baixiang, WACV2021, [database/code](https://github.com/MRUIL/WDNet)<br>
[High Resolution Demoire Network](https://ieeexplore.ieee.org/abstract/document/9191255) -ICIP2020, [code](https://github.com/Rheaaaaayy/HRDN-DEMOIRE)<br>
[BEDSR-Net: A Deep Shadow Removal Network From a Single Document Image](https://openaccess.thecvf.com/content_CVPR_2020/html/Lin_BEDSR-Net_A_Deep_Shadow_Removal_Network_From_a_Single_Document_CVPR_2020_paper.html) -CVPR2020, [code](https://github.com/IsHYuhi/BEDSR-Net_A_Deep_Shadow_Removal_Network_from_a_Single_Document_Image)<br>
